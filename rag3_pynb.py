# -*- coding: utf-8 -*-
"""RAG3.pynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pF2qAVrq0UqFpFt3zKERxubhiwaobWOX
"""

!pip install streamlit pinecone google-generativeai sentence-transformers pypdf

!pip install pytesseract pdf2image Pillow

!pip install python-dotenv

import os
import re
import uuid
import torch
import pypdf
import pytesseract
import numpy as np
from uuid import uuid4
from typing import List, Dict, Tuple, Optional
from collections import defaultdict

import google.generativeai as genai
from pinecone import Pinecone, ServerlessSpec
from sentence_transformers import SentenceTransformer
from pdf2image import convert_from_path
from google.colab import files

from google.colab import files

PINECONE_API_KEY = 'pcsk_6vE8KA_5onMVjpnZhja7eXz263RbA7JtKARSCHpkLQqDExKWMwLLd3uC6dccUVQ7fnmMk7'
PINECONE_INDEX ='rag3'
GENAI_API_KEY = 'AIzaSyBB0irbxOR59HdylF49270dEDI2dNjpWuw'

# Initialize services
pc = Pinecone(api_key=PINECONE_API_KEY)

if PINECONE_INDEX not in [idx.name for idx in pc.list_indexes()]:
    pc.create_index(
        name=PINECONE_INDEX,
        dimension=768,
        metric="cosine",
        spec=ServerlessSpec(cloud="aws", region="us-east-1")
    )

index = pc.Index(PINECONE_INDEX)
genai.configure(api_key=GENAI_API_KEY)

device = 'cuda' if torch.cuda.is_available() else 'cpu'
embed_model = SentenceTransformer('all-mpnet-base-v2', device=device)

print(f"‚úÖ Using device: {device}")
print(f"‚úÖ Embedding dimension: {embed_model.get_sentence_embedding_dimension()}")

class TextProcessor:
    """Advanced text processing with better cleaning and normalization."""

    @staticmethod
    def clean_text(text: str) -> str:
        """Clean and normalize text for better processing."""
        # Remove excessive whitespace and normalize
        text = re.sub(r'\s+', ' ', text)

        # Fix common OCR errors
        text = re.sub(r'([a-z])([A-Z])', r'\1 \2', text)  # Add space between camelCase
        text = re.sub(r'(\w)([.!?])(\w)', r'\1\2 \3', text)  # Add space after punctuation

        # Remove repeated characters (OCR artifacts)
        text = re.sub(r'(.)\1{3,}', r'\1', text)

        # Normalize quotes and dashes
        text = text.replace('"', '"').replace('"', '"')
        text = text.replace(''', "'").replace(''', "'")
        text = text.replace('‚Äì', '-').replace('‚Äî', '-')

        return text.strip()

    @staticmethod
    def extract_sentences(text: str) -> List[str]:
        """Extract sentences with better boundary detection."""
        # Simple sentence splitting with common abbreviations handling
        abbreviations = {'Dr.', 'Mr.', 'Mrs.', 'Ms.', 'Prof.', 'Inc.', 'Ltd.', 'etc.', 'vs.', 'e.g.', 'i.e.'}

        # Replace abbreviations temporarily
        protected_text = text
        for i, abbrev in enumerate(abbreviations):
            protected_text = protected_text.replace(abbrev, f"__ABBREV_{i}__")

        # Split sentences
        sentences = re.split(r'[.!?]+\s+', protected_text)

        # Restore abbreviations
        for i, abbrev in enumerate(abbreviations):
            for j, sentence in enumerate(sentences):
                sentences[j] = sentence.replace(f"__ABBREV_{i}__", abbrev)

        return [s.strip() for s in sentences if s.strip()]

class SmartChunker:
    """Intelligent chunking that preserves semantic coherence."""

    def __init__(self, chunk_size: int = 300, overlap: int = 75, min_chunk_size: int = 50):
        self.chunk_size = chunk_size
        self.overlap = overlap
        self.min_chunk_size = min_chunk_size

    def create_semantic_chunks(self, text: str, page_num: int) -> List[Dict]:
        """Create chunks that respect sentence boundaries and semantic coherence."""
        clean_text = TextProcessor.clean_text(text)
        sentences = TextProcessor.extract_sentences(clean_text)

        if not sentences:
            return []

        chunks = []
        current_chunk = []
        current_length = 0

        for sentence in sentences:
            words = sentence.split()
            sentence_length = len(words)

            # If adding this sentence would exceed chunk size
            if current_length + sentence_length > self.chunk_size and current_chunk:
                # Create chunk from current sentences
                chunk_text = ' '.join(current_chunk)
                if len(chunk_text.split()) >= self.min_chunk_size:
                    chunks.append(self._create_chunk_metadata(chunk_text, page_num, len(chunks)))

                # Start new chunk with overlap
                overlap_sentences = self._get_overlap_sentences(current_chunk, self.overlap)
                current_chunk = overlap_sentences + [sentence]
                current_length = sum(len(s.split()) for s in current_chunk)
            else:
                current_chunk.append(sentence)
                current_length += sentence_length

        # Add final chunk
        if current_chunk:
            chunk_text = ' '.join(current_chunk)
            if len(chunk_text.split()) >= self.min_chunk_size:
                chunks.append(self._create_chunk_metadata(chunk_text, page_num, len(chunks)))

        return chunks

    def _get_overlap_sentences(self, sentences: List[str], overlap_words: int) -> List[str]:
        """Get last few sentences that fit within overlap word limit."""
        overlap_sentences = []
        word_count = 0

        for sentence in reversed(sentences):
            sentence_words = len(sentence.split())
            if word_count + sentence_words <= overlap_words:
                overlap_sentences.insert(0, sentence)
                word_count += sentence_words
            else:
                break

        return overlap_sentences

    def _create_chunk_metadata(self, text: str, page_num: int, chunk_id: int) -> Dict:
        """Create chunk with comprehensive metadata."""
        return {
            'id': str(uuid4()),
            'page': page_num,
            'chunk_id': chunk_id,
            'content': text,
            'word_count': len(text.split()),
            'char_count': len(text)
        }

class ImprovedOCR:
    """Enhanced OCR with better configuration and preprocessing."""

    @staticmethod
    def preprocess_image(image):
        """Apply preprocessing to improve OCR accuracy."""
        import cv2
        import numpy as np
        from PIL import Image

        # Convert PIL to OpenCV format
        opencv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)

        # Convert to grayscale
        gray = cv2.cvtColor(opencv_image, cv2.COLOR_BGR2GRAY)

        # Apply denoising
        denoised = cv2.fastNlMeansDenoising(gray)

        # Improve contrast
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        contrast_enhanced = clahe.apply(denoised)

        # Apply slight blur to smooth text
        blurred = cv2.GaussianBlur(contrast_enhanced, (1, 1), 0)

        # Convert back to PIL
        return Image.fromarray(blurred)

    @staticmethod
    def extract_text_with_enhanced_ocr(pdf_path: str) -> List[Tuple[int, str]]:
        """Extract text using enhanced OCR with preprocessing."""
        print("üîç Converting PDF to images for enhanced OCR processing...")

        try:
            # Higher DPI for better text recognition
            images = convert_from_path(pdf_path, dpi=300, fmt='png')
            print(f"üìÑ Converted PDF to {len(images)} high-resolution images")
        except Exception as e:
            print(f"‚ùå Error converting PDF: {e}")
            return []

        pages = []
        # Enhanced Tesseract configuration
        custom_config = (
            r'--oem 3 --psm 6 '
            r'-c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789.,!?()[]{}:;"\'-_@#$%^&*+=<>/|\\ \n\t '
            r'-c preserve_interword_spaces=1'
        )

        for i, image in enumerate(images):
            print(f"üîÑ Processing page {i+1}/{len(images)} with enhanced OCR...")

            try:
                # Apply preprocessing
                processed_image = ImprovedOCR.preprocess_image(image)

                # Extract text with enhanced config
                text = pytesseract.image_to_string(processed_image, config=custom_config)

                # Clean the extracted text
                cleaned_text = TextProcessor.clean_text(text)

                if cleaned_text and len(cleaned_text.split()) > 5:  # Minimum viable text
                    pages.append((i + 1, cleaned_text))
                    print(f"‚úÖ Page {i+1}: Extracted {len(cleaned_text)} characters, {len(cleaned_text.split())} words")
                else:
                    print(f"‚ö†Ô∏è Page {i+1}: Insufficient text extracted")

            except Exception as e:
                print(f"‚ùå Error processing page {i+1}: {e}")
                continue

        return pages

class HybridRetriever:
    """Advanced retrieval combining multiple strategies."""

    def __init__(self, embed_model, index):
        self.embed_model = embed_model
        self.index = index

    def multi_query_search(self, query: str, top_k: int = 12) -> List[Dict]:
        """Generate multiple query variations for better retrieval."""
        model = genai.GenerativeModel("gemini-2.0-flash-exp")

        # Generate query variations
        variation_prompt = f"""Generate 3 different ways to ask this question, keeping the same meaning but using different words:

Original question: {query}

Return only the 3 variations, one per line, without numbering or extra text."""

        try:
            response = model.generate_content(variation_prompt)
            variations = [line.strip() for line in response.text.strip().split('\n') if line.strip()]
            queries = [query] + variations[:2]  # Original + 2 variations
        except:
            queries = [query]  # Fallback to original query only

        # Search with all query variations
        all_matches = []
        seen_ids = set()

        for i, q in enumerate(queries):
            try:
                query_vec = self.embed_model.encode([q])[0].tolist()
                results = self.index.query(
                    vector=query_vec,
                    top_k=top_k // len(queries) + 2,  # Get more results per query
                    include_metadata=True
                )

                for match in results.matches:
                    if match.id not in seen_ids:
                        match_dict = {
                            'id': match.id,
                            'score': match.score,
                            'metadata': match.metadata,
                            'query_variant': i
                        }
                        all_matches.append(match_dict)
                        seen_ids.add(match.id)

            except Exception as e:
                print(f"‚ö†Ô∏è Error in query variation {i}: {e}")
                continue

        # Sort by score and return top results
        all_matches.sort(key=lambda x: x['score'], reverse=True)
        return all_matches[:top_k]

    def rerank_results(self, matches: List[Dict], query: str) -> List[Dict]:
        """Re-rank results using cross-encoder or keyword matching."""
        # Simple keyword-based re-ranking
        query_words = set(query.lower().split())

        for match in matches:
            content_words = set(match['metadata']['content'].lower().split())
            keyword_overlap = len(query_words.intersection(content_words)) / len(query_words)

            # Combine semantic score with keyword overlap
            match['combined_score'] = match['score'] * 0.7 + keyword_overlap * 0.3

        matches.sort(key=lambda x: x['combined_score'], reverse=True)
        return matches

class AdvancedPDFQASystem:
    """Enhanced PDF QA system with improved accuracy."""

    def __init__(self):
        self.is_processed = False
        self.total_chunks = 0
        self.pdf_name = None
        self.chunker = SmartChunker(chunk_size=300, overlap=75)
        self.retriever = HybridRetriever(embed_model, index)
        self.extraction_stats = {}

    def extract_pages_with_quality_check(self, pdf_path: str) -> List[Tuple[int, str]]:
        """Extract pages with automatic quality assessment."""
        print("üìñ Attempting intelligent text extraction...")

        # Try regular extraction first
        try:
            with open(pdf_path, 'rb') as file:
                reader = pypdf.PdfReader(file)
                pages = []
                total_chars = 0

                for i, page in enumerate(reader.pages):
                    text = page.extract_text()
                    if text:
                        cleaned_text = TextProcessor.clean_text(text)
                        if cleaned_text:
                            pages.append((i + 1, cleaned_text))
                            total_chars += len(cleaned_text)

                # Quality assessment
                if pages:
                    avg_chars = total_chars / len(pages)
                    word_count = sum(len(page[1].split()) for page in pages)
                    avg_words = word_count / len(pages)

                    print(f"üìä Text extraction stats: {len(pages)} pages, avg {avg_chars:.0f} chars/page, {avg_words:.0f} words/page")

                    # If quality is good enough, use text extraction
                    if avg_chars > 200 and avg_words > 30:
                        print("‚úÖ High-quality text extraction successful!")
                        self.extraction_stats = {
                            'method': 'text_extraction',
                            'pages': len(pages),
                            'avg_chars_per_page': avg_chars,
                            'avg_words_per_page': avg_words
                        }
                        return pages

                print("‚ö†Ô∏è Text extraction quality insufficient, switching to enhanced OCR...")

        except Exception as e:
            print(f"‚ùå Text extraction failed: {e}")
            print("üîÑ Switching to enhanced OCR...")

        # Use enhanced OCR
        ocr_pages = ImprovedOCR.extract_text_with_enhanced_ocr(pdf_path)
        if ocr_pages:
            word_count = sum(len(page[1].split()) for page in ocr_pages)
            avg_words = word_count / len(ocr_pages)
            self.extraction_stats = {
                'method': 'enhanced_ocr',
                'pages': len(ocr_pages),
                'avg_words_per_page': avg_words
            }

        return ocr_pages

    def create_and_store_chunks(self, pages: List[Tuple[int, str]]) -> int:
        """Create semantic chunks and store with enhanced metadata."""
        if not pages:
            return 0

        all_chunks = []

        # Create semantic chunks for each page
        for page_num, content in pages:
            page_chunks = self.chunker.create_semantic_chunks(content, page_num)
            all_chunks.extend(page_chunks)

        if not all_chunks:
            return 0

        print(f"üìä Created {len(all_chunks)} semantic chunks from {len(pages)} pages")

        # Generate embeddings
        chunk_texts = [chunk['content'] for chunk in all_chunks]
        print("üîÑ Generating high-quality embeddings...")

        embeddings = embed_model.encode(
            chunk_texts,
            batch_size=16,  # Smaller batch for better quality
            show_progress_bar=True,
            normalize_embeddings=True  # Normalize for better cosine similarity
        )

        # Prepare vectors for Pinecone
        vectors = []
        for i, chunk in enumerate(all_chunks):
            vector_data = {
                "id": chunk['id'],
                "values": embeddings[i].tolist(),
                "metadata": {
                    "page": chunk['page'],
                    "chunk_id": chunk['chunk_id'],
                    "content": chunk['content'],
                    "word_count": chunk['word_count'],
                    "char_count": chunk['char_count']
                }
            }
            vectors.append(vector_data)

        # Upsert to Pinecone in batches
        batch_size = 50  # Smaller batches for reliability
        for i in range(0, len(vectors), batch_size):
            batch = vectors[i:i + batch_size]
            index.upsert(batch)
            print(f"üì§ Uploaded batch {i//batch_size + 1}/{(len(vectors) + batch_size - 1)//batch_size}")

        return len(all_chunks)

    def upload_and_process_pdf(self):
        """Upload and process PDF with enhanced pipeline."""
        print("üìÅ Please upload your PDF file:")
        uploaded = files.upload()

        pdf_path = list(uploaded.keys())[0]
        self.pdf_name = pdf_path

        print(f"üìÑ Processing {pdf_path} with advanced extraction...")

        # Extract with quality assessment
        pages = self.extract_pages_with_quality_check(pdf_path)

        if not pages:
            print("‚ùå No text could be extracted from the PDF")
            return

        print(f"‚úÖ Successfully extracted text from {len(pages)} pages using {self.extraction_stats['method']}")

        # Create and store chunks
        self.total_chunks = self.create_and_store_chunks(pages)

        if self.total_chunks > 0:
            self.is_processed = True
            print(f"‚úÖ Successfully processed PDF:")
            print(f"   üìä {len(pages)} pages extracted")
            print(f"   üß© {self.total_chunks} semantic chunks created")
            print(f"   üîß Method: {self.extraction_stats['method']}")
            print("üéâ Ready for questions!\n")
        else:
            print("‚ùå Failed to create chunks from extracted text")

    def query(self, question: str, top_k: int = 8):
        """Answer questions with enhanced retrieval and generation."""
        if not self.is_processed:
            print("‚ùå Please process a PDF first using upload_and_process_pdf()")
            return

        print(f"üîç Processing question: {question}")

        # Enhanced retrieval with multi-query and re-ranking
        matches = self.retriever.multi_query_search(question, top_k=top_k * 2)
        reranked_matches = self.retriever.rerank_results(matches[:top_k * 2], question)

        if not reranked_matches:
            print("‚ùå No relevant content found for your query.")
            return

        # Group and combine by page
        page_content = self._combine_chunks_intelligently(reranked_matches[:top_k])

        print(f"\nüìã Retrieved content from {len(page_content)} page(s):")
        for i, page_info in enumerate(page_content[:4], 1):
            print(f"  {i}. Page {page_info['page']} (Score: {page_info['combined_score']:.3f}, {page_info['chunk_count']} chunks)")

        # Generate enhanced answer
        answer = self._generate_enhanced_answer(page_content[:4], question)

        print("\n" + "="*70)
        print("üìù ANSWER:")
        print("="*70)
        print(answer)
        print("="*70)
        print(f"üìä Answer based on {len(page_content)} relevant page(s)")

    def _combine_chunks_intelligently(self, matches: List[Dict]) -> List[Dict]:
        """Intelligently combine chunks by page with deduplication."""
        page_groups = defaultdict(list)

        for match in matches:
            page_num = match['metadata']['page']
            page_groups[page_num].append(match)

        combined_pages = []
        for page_num, page_matches in page_groups.items():
            # Sort chunks by chunk_id to maintain order
            page_matches.sort(key=lambda x: x['metadata']['chunk_id'])

            # Combine content while removing overlap
            combined_content = self._merge_overlapping_chunks(
                [m['metadata']['content'] for m in page_matches]
            )

            avg_score = np.mean([m['combined_score'] for m in page_matches])

            combined_pages.append({
                'page': page_num,
                'content': combined_content,
                'combined_score': avg_score,
                'chunk_count': len(page_matches),
                'word_count': len(combined_content.split())
            })

        return sorted(combined_pages, key=lambda x: x['combined_score'], reverse=True)

    def _merge_overlapping_chunks(self, chunks: List[str]) -> str:
        """Merge overlapping chunks while removing redundancy."""
        if not chunks:
            return ""

        if len(chunks) == 1:
            return chunks[0]

        # Simple overlap removal - join with minimal redundancy
        merged = chunks[0]

        for chunk in chunks[1:]:
            # Find best overlap point
            words_merged = merged.split()
            words_chunk = chunk.split()

            # Look for overlap in last 20 words of merged with first 20 of chunk
            best_overlap = 0
            overlap_start = len(words_merged)

            for i in range(1, min(21, len(words_merged), len(words_chunk)) + 1):
                if words_merged[-i:] == words_chunk[:i]:
                    if i > best_overlap:
                        best_overlap = i
                        overlap_start = len(words_merged) - i

            if best_overlap > 0:
                merged = ' '.join(words_merged[:overlap_start] + words_chunk)
            else:
                merged += ' ' + chunk

        return merged

    def _generate_enhanced_answer(self, page_data: List[Dict], question: str) -> str:
        """Generate answer with enhanced prompting."""
        model = genai.GenerativeModel("gemini-2.0-flash-exp")

        # Format context with page information
        formatted_content = ""
        for page_info in page_data:
            formatted_content += f"\n=== PAGE {page_info['page']} (Relevance: {page_info['combined_score']:.3f}) ===\n"
            formatted_content += page_info['content'] + "\n"

        # Enhanced prompt for better accuracy
        prompt = f"""You are an expert document analyst. Answer the question based ONLY on the provided document content.

DOCUMENT CONTENT:
{formatted_content}

QUESTION: {question}

INSTRUCTIONS:
1. Provide a comprehensive, accurate answer using ONLY the information from the document
2. If the answer spans multiple pages, synthesize information coherently
3. Always cite specific page numbers when referencing information (e.g., "According to page 3...")
4. If information is incomplete, clearly state what additional details would be needed
5. Be precise and avoid speculation beyond what's explicitly stated
6. Structure your answer logically with clear reasoning
7. If no relevant information is found, state this clearly

ANSWER:"""

        try:
            response = model.generate_content(
                prompt,
                generation_config={
                    'temperature': 0.1,  # Lower temperature for more factual responses
                    'top_p': 0.8,
                    'max_output_tokens': 1000
                }
            )
            return response.text
        except Exception as e:
            return f"‚ùå Error generating answer: {str(e)}"


# Initialize the enhanced system
qa_system = AdvancedPDFQASystem()

print("üöÄ Advanced PDF QA System Ready!")
print("üìã Enhanced Features:")
print("  ‚úÖ Smart text extraction with quality assessment")
print("  ‚úÖ Enhanced OCR with image preprocessing")
print("  ‚úÖ Semantic-aware chunking")
print("  ‚úÖ Multi-query retrieval with re-ranking")
print("  ‚úÖ Intelligent chunk combination")
print("  ‚úÖ Enhanced answer generation")
print("\nüìã Instructions:")
print("1. Run: qa_system.upload_and_process_pdf()")
print("2. Run: qa_system.query('your question here')")

qa_system = AdvancedPDFQASystem()

qa_system.upload_and_process_pdf()

qa_system.query("Name of Managing director")